{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Week 4 \u2014 GT\u2011Full Toy Node Labeling\n",
        "We compare a simple MLP baseline against a **GT\u2011Full** message\u2011passing model on a toy relational graph.\n",
        "GT\u2011Full uses **relation\u2011aware simplicial message passing** (edge types) and should learn faster.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "torch.manual_seed(0)\n",
        "np.random.seed(0)\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print('Device:', device)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1) Build a toy relational graph\n",
        "We create two relation types: `friend` and `colleague`.\n",
        "Labels are a simple function of relation\u2011specific neighborhood counts.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Toy graph\n",
        "N = 80\n",
        "rel_names = ['friend', 'colleague']\n",
        "num_rel = len(rel_names)\n",
        "\n",
        "# Random edges with relation types\n",
        "edges_src = []\n",
        "edges_dst = []\n",
        "rel_ids = []\n",
        "\n",
        "rng = np.random.default_rng(0)\n",
        "for i in range(N):\n",
        "    for j in range(N):\n",
        "        if i == j:\n",
        "            continue\n",
        "        p = rng.random()\n",
        "        if p < 0.07:\n",
        "            r = 0  # friend\n",
        "        elif p < 0.11:\n",
        "            r = 1  # colleague\n",
        "        else:\n",
        "            continue\n",
        "        edges_src.append(i)\n",
        "        edges_dst.append(j)\n",
        "        rel_ids.append(r)\n",
        "\n",
        "edge_index = torch.tensor([edges_src, edges_dst], dtype=torch.long)\n",
        "rel_ids = torch.tensor(rel_ids, dtype=torch.long)\n",
        "\n",
        "# Node features are pure noise (baseline cannot use relations)\n",
        "X = torch.randn(N, 8)\n",
        "\n",
        "# Labels depend on relation-aware neighborhood counts\n",
        "deg_friend = torch.zeros(N)\n",
        "deg_coll   = torch.zeros(N)\n",
        "for s, d, r in zip(edges_src, edges_dst, rel_ids.tolist()):\n",
        "    if r == 0:\n",
        "        deg_friend[d] += 1\n",
        "    else:\n",
        "        deg_coll[d] += 1\n",
        "\n",
        "score = deg_friend - deg_coll\n",
        "# Balanced labels by median threshold\n",
        "thr = torch.median(score)\n",
        "y = (score > thr).long()\n",
        "\n",
        "# Stratified train/val split\n",
        "idx0 = torch.where(y == 0)[0]\n",
        "idx1 = torch.where(y == 1)[0]\n",
        "idx0 = idx0[torch.randperm(len(idx0))]\n",
        "idx1 = idx1[torch.randperm(len(idx1))]\n",
        "train_idx = torch.cat([idx0[:25], idx1[:25]])\n",
        "val_idx   = torch.cat([idx0[25:], idx1[25:]])\n",
        "\n",
        "# shuffle train/val indices\n",
        "train_idx = train_idx[torch.randperm(len(train_idx))]\n",
        "val_idx = val_idx[torch.randperm(len(val_idx))]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2) Baseline vs GT\u2011Full model\n",
        "The baseline ignores relations and only uses node features.\n",
        "GT\u2011Full aggregates relation\u2011aware messages along edges.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# GT\u2011Full message passing from the repo (minimal copy)\n",
        "class SimplicialMessagePassing(nn.Module):\n",
        "    def __init__(self, dim: int, num_rel: int, hidden_dim: int | None = None):\n",
        "        super().__init__()\n",
        "        hidden_dim = hidden_dim or dim\n",
        "        self.edge_mlp = nn.Sequential(\n",
        "            nn.Linear(2 * dim + num_rel, hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden_dim, dim),\n",
        "        )\n",
        "\n",
        "    def forward(self, V, edge_index, rel_ids):\n",
        "        if edge_index.shape[0] == 2:\n",
        "            src = edge_index[0].long()\n",
        "            dst = edge_index[1].long()\n",
        "        else:\n",
        "            src = edge_index[:,0].long()\n",
        "            dst = edge_index[:,1].long()\n",
        "        src_h = V[src]\n",
        "        dst_h = V[dst]\n",
        "        num_rel = int(rel_ids.max().item()) + 1 if rel_ids.numel() > 0 else 0\n",
        "        rel_onehot = F.one_hot(rel_ids.long(), num_classes=num_rel).float()\n",
        "        edge_feat = torch.cat([src_h, dst_h, rel_onehot], dim=-1)\n",
        "        msg = self.edge_mlp(edge_feat)\n",
        "        out = torch.zeros_like(V)\n",
        "        out.index_add_(0, dst, msg)\n",
        "        return V + out\n",
        "\n",
        "class GeometricTransformerV2(nn.Module):\n",
        "    def __init__(self, dim: int, depth: int, num_rel: int):\n",
        "        super().__init__()\n",
        "        self.layers = nn.ModuleList([SimplicialMessagePassing(dim, num_rel) for _ in range(depth)])\n",
        "        self.norm = nn.LayerNorm(dim)\n",
        "\n",
        "    def forward(self, V, edge_index, rel_ids):\n",
        "        h = V\n",
        "        for layer in self.layers:\n",
        "            h = layer(h, edge_index, rel_ids)\n",
        "        return self.norm(h)\n",
        "\n",
        "class BaselineMLP(nn.Module):\n",
        "    def __init__(self, in_dim, hidden=32):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(in_dim, hidden),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden, 2),\n",
        "        )\n",
        "    def forward(self, x):\n",
        "        return self.net(x)\n",
        "\n",
        "class GTFullClassifier(nn.Module):\n",
        "    def __init__(self, in_dim, hidden=32, depth=2, num_rel=2):\n",
        "        super().__init__()\n",
        "        self.in_proj = nn.Linear(in_dim, hidden)\n",
        "        self.gt = GeometricTransformerV2(hidden, depth, num_rel)\n",
        "        self.out = nn.Linear(hidden, 2)\n",
        "    def forward(self, x, edge_index, rel_ids):\n",
        "        h = self.in_proj(x)\n",
        "        h = self.gt(h, edge_index, rel_ids)\n",
        "        return self.out(h)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3) Train and compare\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "def train_model(model, is_gt=False, epochs=400, lr=3e-3, weight_decay=1e-3):\n",
        "    model = model.to(device)\n",
        "    opt = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
        "    logs = []\n",
        "    best = 0.0\n",
        "    for epoch in range(1, epochs+1):\n",
        "        model.train()\n",
        "        if is_gt:\n",
        "            logits = model(X.to(device), edge_index.to(device), rel_ids.to(device))\n",
        "        else:\n",
        "            logits = model(X.to(device))\n",
        "        loss = F.cross_entropy(logits[train_idx], y[train_idx].to(device))\n",
        "        opt.zero_grad()\n",
        "        loss.backward()\n",
        "        opt.step()\n",
        "        with torch.no_grad():\n",
        "            preds = logits.argmax(dim=-1).cpu()\n",
        "            acc = (preds[val_idx] == y[val_idx]).float().mean().item()\n",
        "        best = max(best, acc)\n",
        "        logs.append((loss.item(), acc, best))\n",
        "    return logs\n",
        "\n",
        "baseline = BaselineMLP(in_dim=8)\n",
        "gtfull = GTFullClassifier(in_dim=8, depth=2, num_rel=num_rel)\n",
        "\n",
        "b_logs = train_model(baseline, is_gt=False, epochs=400, lr=3e-3, weight_decay=1e-3)\n",
        "g_logs = train_model(gtfull, is_gt=True, epochs=400, lr=3e-3, weight_decay=1e-3)\n",
        "\n",
        "plt.figure(figsize=(6,4))\n",
        "plt.plot([x[2] for x in b_logs], label='Baseline MLP (best-so-far)')\n",
        "plt.plot([x[2] for x in g_logs], label='GT\u2011Full (best-so-far)')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Val accuracy (best\u2011so\u2011far)')\n",
        "plt.title('GT\u2011Full vs baseline on relational labels')\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "week04_gt_full_node_labeling.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python",
      "version": "3.x"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}