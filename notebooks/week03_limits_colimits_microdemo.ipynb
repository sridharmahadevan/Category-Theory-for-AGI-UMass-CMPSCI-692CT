{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "605d685a",
   "metadata": {},
   "source": [
    "# Week 3 — Limits & Colimits (Micro‑Demos)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3221a728",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/sridharmahadevan/Category-Theory-for-AGI-UMass-CMPSCI-692CT/blob/main/notebooks/week03_limits_colimits_microdemo.ipynb)\n",
    "<br/>\n",
    "_Replace `sridharmahadevan/Category-Theory-for-AGI-UMass-CMPSCI-692CT` above once you push this repo to GitHub._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9df4dcb",
   "metadata": {},
   "source": [
    "### Environment (run first)\n",
    "This pins a minimal, stable stack. GPU is **optional**; notebooks run on CPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24ab6dc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "# Core scientific stack + causal / graph tooling\n",
    "%pip install -q numpy==1.* pandas==2.* matplotlib==3.* networkx==3.* pgmpy==0.1.* graphviz==0.20.*\n",
    "# Torch CPU by default (Colab often preinstalls a GPU build; this is a safe fallback)\n",
    "%pip install -q torch --extra-index-url https://download.pytorch.org/whl/cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "369b614c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install system graphviz only if available (Colab & many Linux envs). Safe to skip elsewhere.\n",
    "!command -v apt-get >/dev/null && apt-get -y -qq install graphviz || echo \"apt-get not available; skipping system graphviz\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e03cb5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import platform, sys\n",
    "print(\"Python:\", platform.python_version())\n",
    "try:\n",
    "    import torch\n",
    "    print(\"Torch:\", torch.__version__, \"| CUDA available?\", torch.cuda.is_available())\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "except Exception as e:\n",
    "    print(\"Torch not installed, proceeding CPU-only.\")\n",
    "    device = \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5a03de1",
   "metadata": {},
   "source": [
    "\n",
    "## Learning goals\n",
    "- Compute a **pullback** (limit) in **Set** for two functions \\(X\\xrightarrow{f} Z\\xleftarrow{g} Y\\).\n",
    "- Compute a **pushout** (colimit) in **Set** for \\(X\\xleftarrow{u} W\\xrightarrow{v} Y\\) as quotient (gluing).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d2b16c5",
   "metadata": {},
   "source": [
    "## Pullback demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df4fcd0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X = {\"x0\",\"x1\",\"x2\"}\n",
    "Y = {\"y0\",\"y1\"}\n",
    "Z = {\"z0\",\"z1\"}\n",
    "\n",
    "f = {\"x0\":\"z0\", \"x1\":\"z1\", \"x2\":\"z1\"}  # X→Z\n",
    "g = {\"y0\":\"z1\", \"y1\":\"z0\"}             # Y→Z\n",
    "\n",
    "pullback = {(x,y) for x in X for y in Y if f[x] == g[y]}\n",
    "print(\"Pullback X×_Z Y =\", pullback)  # pairs with matching images\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "856c16c3",
   "metadata": {},
   "source": [
    "## Pushout demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a940f900",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# W injects into X and Y via u and v. Identify points with same preimage.\n",
    "W = {\"w0\",\"w1\"}\n",
    "X = {\"x0\",\"x1\",\"x2\"}\n",
    "Y = {\"y0\",\"y1\"}\n",
    "u = {\"w0\":\"x1\", \"w1\":\"x2\"}   # W→X\n",
    "v = {\"w0\":\"y0\", \"w1\":\"y1\"}   # W→Y\n",
    "\n",
    "# Disjoint union X ⊔ Y represented as tagged elements\n",
    "disjoint = {(\"X\",x) for x in X} | {(\"Y\",y) for y in Y}\n",
    "\n",
    "# Equivalence relation generated by u(w) ~ v(w)\n",
    "parent = {e:e for e in disjoint}\n",
    "def find(a):\n",
    "    while parent[a]!=a:\n",
    "        parent[a]=parent[parent[a]]\n",
    "        a=parent[a]\n",
    "    return a\n",
    "def union(a,b):\n",
    "    ra, rb = find(a), find(b)\n",
    "    if ra!=rb: parent[rb]=ra\n",
    "\n",
    "for w in W:\n",
    "    union((\"X\", u[w]), (\"Y\", v[w]))\n",
    "\n",
    "# Compute quotient classes = pushout\n",
    "classes = {}\n",
    "for e in disjoint:\n",
    "    classes.setdefault(find(e), set()).add(e)\n",
    "\n",
    "pushout = list(classes.values())\n",
    "print(\"Pushout (X ⊔ Y)/~ has classes:\")\n",
    "for c in pushout:\n",
    "    print(sorted(map(str,c)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc701b6a",
   "metadata": {},
   "source": [
    "## Exercises"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6285b1dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 1) Modify f and g and re-run to see how the pullback changes; verify projections commute.\n",
    "# 2) Add another w2 in W that glues x0 with y1 and see new pushout quotient classes.\n",
    "# 3) Prove (by code) the universal property: any cone to Z factors uniquely through the pullback.\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}